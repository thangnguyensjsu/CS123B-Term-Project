{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI/ML methods notebook\n",
        "\n"
      ],
      "metadata": {
        "id": "QG3X-tGIpkMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install Python packages\n",
        "This notebook is equipped with a dedicated login shell, tailored to the environment in which it is executed. If you are utilizing your personal compute system, such as a laptop, the login corresponds to your individual compute system login. Conversely, when running this notebook on Google Colab, the login is attributed to the root user. The initiation of Linux shell commands within Jupyter notebook code cells is denoted by a preceding exclamation point (!).\n",
        "\n",
        "In the code cell below, the provided pip commands are employed to install a range of Python libraries essential for the tasks covered in this notebook. It's worth noting that additional Python libraries are automatically installed within our virtual environment."
      ],
      "metadata": {
        "id": "gMEmAFI5sAuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn --no-cache\n",
        "!pip install scanpy --no-cache\n",
        "!pip install gseapy --no-cache\n",
        "!pip install pybiomart==0.1 --no-cache\n",
        "#!pip install mygene --no-cache\n",
        "!pip install sklearn_som  --no-cache\n",
        "!pip install pandas --no-cache\n",
        "!pip install numpy --no-cache\n",
        "!pip install matplotlib --no-cache\n",
        "!pip install sklearn-som --no-cache\n",
        "!pip install pyDeseq2 --no-cache\n",
        "!pip install Ensembl_converter --no-cache\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "bb8-MziuOeFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c853a7bf-ecee-4b9c-b300-8c70c043ba10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.11.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.11.4-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.4.2)\n",
            "Collecting legacy-api-wrap>=1.4 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.4.2)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (24.2)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.13)\n",
            "Collecting scikit-learn<1.6.0,>=1.1 (from scanpy)\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.14.1)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.13.2)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Downloading session_info2-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.13.0)\n",
            "Requirement already satisfied: umap-learn!=0.5.0,>=0.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.7)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7->scanpy) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->scanpy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.1->scanpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->scanpy) (1.17.0)\n",
            "Downloading scanpy-1.11.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.11.4-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m250.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m220.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading session_info2-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading array_api_compat-1.11.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m191.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: session-info2, legacy-api-wrap, array-api-compat, scikit-learn, anndata, scanpy\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed anndata-0.11.4 array-api-compat-1.11.2 legacy-api-wrap-1.4.1 scanpy-1.11.1 scikit-learn-1.5.2 session-info2-0.1.2\n",
            "Collecting gseapy\n",
            "  Downloading gseapy-1.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gseapy) (1.14.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.11/dist-packages (from gseapy) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gseapy) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2->gseapy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gseapy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gseapy) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gseapy) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->gseapy) (1.17.0)\n",
            "Downloading gseapy-1.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.8/590.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gseapy\n",
            "Successfully installed gseapy-1.1.8\n",
            "Collecting pybiomart==0.1\n",
            "  Downloading pybiomart-0.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pybiomart==0.1) (2.32.3)\n",
            "Collecting requests_cache (from pybiomart==0.1)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pybiomart==0.1) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pybiomart==0.1) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests_cache->pybiomart==0.1) (25.3.0)\n",
            "Collecting cattrs>=22.2 (from requests_cache->pybiomart==0.1)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests_cache->pybiomart==0.1) (4.3.7)\n",
            "Collecting url-normalize>=1.4 (from requests_cache->pybiomart==0.1)\n",
            "  Downloading url_normalize-2.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pybiomart==0.1) (1.17.0)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m201.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-2.2.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: pybiomart\n",
            "  Building wheel for pybiomart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybiomart: filename=pybiomart-0.1-py3-none-any.whl size=14600 sha256=d4d31738c1dcfb41fb1eeb810ffb7aac2beba02affe28be2b46635baf8419e13\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9s8czuel/wheels/ad/45/48/b79ec13dfdbc57735df3c6e295b70f4db768335832c07bfc57\n",
            "Successfully built pybiomart\n",
            "Installing collected packages: url-normalize, cattrs, requests_cache, pybiomart\n",
            "Successfully installed cattrs-24.1.3 pybiomart-0.1 requests_cache-1.2.1 url-normalize-2.2.0\n",
            "Collecting sklearn_som\n",
            "  Downloading sklearn_som-1.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sklearn_som) (2.0.2)\n",
            "Downloading sklearn_som-1.1.0-py3-none-any.whl (6.7 kB)\n",
            "Installing collected packages: sklearn_som\n",
            "Successfully installed sklearn_som-1.1.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: sklearn-som in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sklearn-som) (2.0.2)\n",
            "Collecting pyDeseq2\n",
            "  Downloading pydeseq2-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: anndata>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (0.11.4)\n",
            "Collecting formulaic>=1.0.2 (from pyDeseq2)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (1.14.1)\n",
            "Collecting formulaic-contrasts>=0.2.0 (from pyDeseq2)\n",
            "  Downloading formulaic_contrasts-1.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from pyDeseq2) (3.10.0)\n",
            "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (1.11.2)\n",
            "Requirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (3.13.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (8.4.0)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8.0->pyDeseq2) (24.2)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.2->pyDeseq2)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.2->pyDeseq2) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=1.0.2->pyDeseq2) (1.17.2)\n",
            "Collecting session-info (from formulaic-contrasts>=0.2.0->pyDeseq2)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.2->pyDeseq2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->pyDeseq2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->pyDeseq2) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->pyDeseq2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->pyDeseq2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->pyDeseq2) (1.17.0)\n",
            "Collecting stdlib_list (from session-info->formulaic-contrasts>=0.2.0->pyDeseq2)\n",
            "  Downloading stdlib_list-0.11.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading pydeseq2-0.5.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic_contrasts-1.0.0-py3-none-any.whl (10 kB)\n",
            "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading stdlib_list-0.11.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: session-info\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8024 sha256=5a7f50df4c1552c08c0718f86dec715c539301b9fd0e6457c391e1e1c233c01f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lkeyaxh1/wheels/4e/56/35/a748fc57279a4b84d0b332879445fed1ad8478e7257986b015\n",
            "Successfully built session-info\n",
            "Installing collected packages: stdlib_list, interface-meta, session-info, formulaic, formulaic-contrasts, pyDeseq2\n",
            "Successfully installed formulaic-1.1.1 formulaic-contrasts-1.0.0 interface-meta-1.3.0 pyDeseq2-0.5.0 session-info-1.0.0 stdlib_list-0.11.1\n",
            "Collecting Ensembl_converter\n",
            "  Downloading ensembl_converter-0.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Ensembl_converter) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Ensembl_converter) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Ensembl_converter) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Ensembl_converter) (1.17.0)\n",
            "Downloading ensembl_converter-0.0.1-py3-none-any.whl (4.3 kB)\n",
            "Installing collected packages: Ensembl_converter\n",
            "Successfully installed Ensembl_converter-0.0.1\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import Python modules"
      ],
      "metadata": {
        "id": "cpkDoGrUsMlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook imports a number of Python modules for use in several notebooks."
      ],
      "metadata": {
        "id": "uSnhzxTaLN9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn_som.som import SOM\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import scanpy as sc\n",
        "import gseapy as gp\n",
        "from gseapy.plot import gseaplot\n",
        "from pydeseq2.dds import DeseqDataSet\n",
        "from pydeseq2.ds import DeseqStats\n",
        "from gseapy import Msigdb\n",
        "from pybiomart import Server\n",
        "#import mygene\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import TweedieRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from math import log\n",
        "import statsmodels.api as sm\n",
        "import pylab\n",
        "import operator\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, PrecisionRecallDisplay\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from itertools import islice\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import scipy.stats as stats\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from Ensembl_converter import EnsemblConverter\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance\n",
        "from google.colab import data_table\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from vega_datasets import data"
      ],
      "metadata": {
        "id": "f079g46t5jTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define misc helper methods"
      ],
      "metadata": {
        "id": "xxokeQF9rjFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_maxdisplay(n=None):\n",
        "  pd.set_option('display.max_rows', n)\n",
        "  from notebook.services.config import ConfigManager\n",
        "  cm = ConfigManager().update('notebook', {'limit_output': n})"
      ],
      "metadata": {
        "id": "EpOLwn3YqdYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define data ingestion methods"
      ],
      "metadata": {
        "id": "W_cXRde853Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_meta_data(dataset):\n",
        "  # dataset=255\n",
        "  url = 'https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=OSD-' + dataset + '_metadata_OSD-' + dataset + '-ISA.zip'\n",
        "  filename = dataset + '-meta.zip'\n",
        "  urlretrieve(url, filename)\n",
        "  !unzip -o {filename} > /dev/null\n",
        "  df = pd.read_csv('s_OSD-' + dataset + '.txt', sep='\\t', header=0)\n",
        "  return df"
      ],
      "metadata": {
        "id": "LwoDZ49r7i_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_behavior_data(dataset, data):\n",
        "  # dataset = '557'\n",
        "  # data = 'LSDS-1_immunostaining_microscopy_PNAtr_Transformed_Reusable_Results'\n",
        "  url='https://osdr.nasa.gov//geode-py/ws/studies/OSD-' + str(dataset) + '/download?file=' + data + '.csv&version=1'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ],
      "metadata": {
        "id": "rOt8cADMclf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_flowcytometry_data(dataset, data):\n",
        "  # dataset = '557'\n",
        "  # data = 'LSDS-1_immunostaining_microscopy_PNAtr_Transformed_Reusable_Results'\n",
        "  url='https://osdr.nasa.gov//geode-py/ws/studies/OSD-' + str(dataset) + '/download?file=' + data + '.csv&version=1'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ],
      "metadata": {
        "id": "yCVR-HkZn08K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_display_confusion_matrix(Y_test, final_predictions):\n",
        "\n",
        "  # Convert string labels to numerical labels 0 and 1\n",
        "  Y_test_numeric = np.where(Y_test == 'pos', 1, 0)\n",
        "  final_predictions_numeric = np.where(final_predictions == 'pos', 1, 0)\n",
        "\n",
        "  # Confusion Matrix\n",
        "  cm = confusion_matrix(Y_test_numeric, final_predictions_numeric)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"neg\", \"pos\"])\n",
        "  print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "  # Plot\n",
        "  disp.plot(cmap='Blues')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "exHQRY7kFCCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define data filtering methods"
      ],
      "metadata": {
        "id": "7Ga9Pbi5rr1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_digit(sample_name):\n",
        "    try:\n",
        "        # Convert to string, split, and get the second element (index 1)\n",
        "        digit = str(sample_name).split('_')[0]\n",
        "        # Attempt to convert to an integer, if it fails return None\n",
        "        return int(digit)\n",
        "    except (IndexError, ValueError, TypeError):\n",
        "        return None"
      ],
      "metadata": {
        "id": "LOFpz3WxkRsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_assay(sample_name):\n",
        "    try:\n",
        "        parts = str(sample_name).split('_')\n",
        "        assay_name = parts[1]\n",
        "        return assay_name\n",
        "    except (IndexError, TypeError):\n",
        "        return None"
      ],
      "metadata": {
        "id": "cvO_jxG1iEjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_nans(df):\n",
        "  # drop NaN rows\n",
        "  df.dropna(inplace=False)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "0kMwy7X10hxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data transformation methods"
      ],
      "metadata": {
        "id": "d4IuHC13rGZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_ml(x, y, test_size=0.2, random_state=42):\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Separate numerical and categorical columns\n",
        "    df_num = x.drop(['Factor Value[Sex]', 'Factor Value[Treatment]', 'Factor Value[Ionizing Radiation]'], axis=1)\n",
        "    df_cat_treatment = x[['Factor Value[Treatment]']]\n",
        "    df_cat_gender = x[['Factor Value[Sex]']]\n",
        "    df_cat_rad = x[['Factor Value[Ionizing Radiation]']]\n",
        "\n",
        "    # Numerical pipeline\n",
        "    num_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Categorical pipelines (One-hot encoding)\n",
        "    categorical_features = ['Factor Value[Sex]', 'Factor Value[Treatment]', 'Factor Value[Ionizing Radiation]']\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', num_pipeline, list(df_num.columns)),\n",
        "            ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_train_prepared = preprocessor.fit_transform(X_train)\n",
        "    X_test_prepared = preprocessor.transform(X_test)\n",
        "\n",
        "    # Get column names for transformed data\n",
        "    num_columns = df_num.columns\n",
        "    cat_columns = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
        "    all_columns = np.concatenate([cat_columns, num_columns])\n",
        "\n",
        "    # Convert transformed data to DataFrames\n",
        "    X_train_prepared_df = pd.DataFrame(X_train_prepared, columns=all_columns, index=X_train.index)\n",
        "    X_test_prepared_df = pd.DataFrame(X_test_prepared, columns=all_columns, index=X_test.index)\n",
        "\n",
        "    return X_train_prepared_df, X_test_prepared_df, Y_train, Y_test"
      ],
      "metadata": {
        "id": "5fQ-cypLvzxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plotting methods"
      ],
      "metadata": {
        "id": "EYvmAZ627HKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_numerical_features(dataframe, cols_per_row=3, bins=10):\n",
        "\n",
        "    dataframe['RAWM_D1_Block1_Errors'] = pd.to_numeric(dataframe['RAWM_D1_Block1_Errors'], errors='coerce')\n",
        "    numerical_cols = dataframe.select_dtypes(include=['number']).columns\n",
        "    numerical_cols = numerical_cols[numerical_cols != 'Source Name']\n",
        "\n",
        "    num_plots = len(numerical_cols)\n",
        "    num_rows = (num_plots + cols_per_row - 1) // cols_per_row\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, cols_per_row, figsize=(17, 5 * num_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(numerical_cols):\n",
        "        if i < num_plots:\n",
        "            axes[i].hist(dataframe[col], bins=bins)\n",
        "            axes[i].set_title(col)\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel(\"Frequency\")\n",
        "        else:\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Qw9mhF_6x4hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_target_distribution(dataframe, target_column):\n",
        "    # Calculate class counts and distribution\n",
        "    class_counts = dataframe[target_column].value_counts()\n",
        "    class_distribution = class_counts / len(dataframe)\n",
        "\n",
        "    # Print class counts and distribution\n",
        "    print(\"Class Counts:\\n\", class_counts)\n",
        "    print(\"\\nClass Distribution:\\n\", class_distribution)\n",
        "\n",
        "    # Create a bar plot\n",
        "    plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
        "    class_distribution.plot(kind='bar', color=['skyblue', 'salmon'])  # Customize colors\n",
        "    plt.title(f'Class Distribution of {target_column}')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Proportion')\n",
        "    plt.xticks(rotation=0)  # Keep x-axis labels horizontal\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9WzGiPaqzNsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(model, X_test, Y_test, pos_label='pos'):\n",
        "\n",
        "  plt.figure(figsize=(10, 8))\n",
        "\n",
        "  # Get predicted probabilities for the positive class\n",
        "  clf_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate ROC curve and AUC\n",
        "  fpr, tpr, thresholds = roc_curve(Y_test, clf_probs, pos_label=pos_label)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  # Plot the ROC curve\n",
        "  plt.plot(fpr, tpr, lw=2, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "  # Plot the diagonal line (random classifier)\n",
        "  plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
        "\n",
        "  # Set plot limits and labels\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "odKo9MRQEgdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# machine learning methods\n"
      ],
      "metadata": {
        "id": "3UrOPfUfTfXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_models(X_train_prepared_df, X_test_prepared_df, Y_train, Y_test, models_to_use = None):\n",
        "  models={\n",
        "  'LogisticRegression':LogisticRegression(),\n",
        "  'KNeighborsClassifier':KNeighborsClassifier(),\n",
        "  'SVC':SVC(probability=True),\n",
        "  'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
        "  'RandomForestClassifier':RandomForestClassifier(),\n",
        "  }\n",
        "\n",
        "  if models_to_use:\n",
        "    # Filter models dictionary based on models_to_use list\n",
        "    models = {key: value for key, value in models.items() if key in models_to_use}\n",
        "\n",
        "  for model_name, model in models.items():\n",
        "    #training the model on training data\n",
        "    model.fit(X_train_prepared_df,Y_train)\n",
        "    #making predictions on the test data\n",
        "    Y_pred=model.predict(X_test_prepared_df)\n",
        "    #printing classification report which contains accuracy\n",
        "    print(models[model_name], classification_report(Y_test, Y_pred))\n",
        "  return models"
      ],
      "metadata": {
        "id": "hK211U2GDN4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_knn_model(X_train, y_train):\n",
        "  param_grid = [\n",
        "      {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
        "  ]\n",
        "\n",
        "  knn_clf = KNeighborsClassifier()\n",
        "  grid_search = GridSearchCV(knn_clf, param_grid, cv=5,\n",
        "                             scoring='accuracy', return_train_score=True)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  print(\"Best parameters:\", grid_search.best_params_)\n",
        "  print(\"Best cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "  return grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "Ty58nTjpEH3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}